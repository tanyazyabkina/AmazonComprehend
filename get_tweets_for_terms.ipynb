{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Twitter Dataset\n",
    "Query Twitter for terms of interest and download tweets for further analysis using NLP tools (AWS Comprehend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import pandas as pd\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"insert_your_key\"\n",
    "consumer_secret = \"insert_your_key\"\n",
    "access_key = \"insert_your_key\"\n",
    "access_secret = \"insert_your_key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tweets that mention Kroger and are not retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method allows us to query last 7 days of tweets\n",
    "\n",
    "query = \"kroger -filter:retweets\"\n",
    "\n",
    "# Initiate the list\n",
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search, \n",
    "                           q=query,\n",
    "                           count=100,\n",
    "                           lang=\"en\",\n",
    "                           tweet_mode=\"extended\").items(10000):\n",
    "    tweets.append(tweet._json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tweets\n",
    "# sometimes there are fewer than 10K tweets on certain topic\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who cheaper Kroger or Walmart?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample tweet\n",
    "tweets[100]['full_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert JSON file into a dataframe of select tweet fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len (tweets)):\n",
    "    retweet_name = ''\n",
    "    try:\n",
    "        x = tweets[i]['retweeted_status']['full_text']\n",
    "        retweet = True\n",
    "        retweet_name = tweets[i]['retweeted_status']['user']['screen_name']\n",
    "            \n",
    "    except KeyError:\n",
    "        x = tweets[i]['full_text']\n",
    "        retweet = False\n",
    "        retweet_name = ''\n",
    "    df = pd.DataFrame({'user': tweets[i]['user']['screen_name'],\n",
    "                       'id_str': tweets[i]['id_str'],\n",
    "                       'created_at': tweets[i]['created_at'],\n",
    "                       'source': tweets[i]['source'],\n",
    "                       'in_reply_to_screen_name': tweets[i]['in_reply_to_screen_name'],\n",
    "                       'full_text':x,\n",
    "                       'rt': retweet,\n",
    "                       'rt_name': retweet_name}, index = [i])\n",
    "    tweet_df = tweet_df.append(df)\n",
    "\n",
    "tweet_df.created_at = pd.to_datetime(tweet_df.created_at) - pd.Timedelta(5, unit = 'h') #GMT +5 timezone\n",
    "tweet_df.id_str = 'id = '+tweet_df.id_str # helps with CSV to Excel transition\n",
    "\n",
    "# Amazon Comrehend prep\n",
    "# remove line breaks in tweets\n",
    "tweet_df.full_text = tweet_df.full_text.str.replace('\\n', ' ')\n",
    "tweet_df.full_text = tweet_df.full_text.str.replace('\\r', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../NLP/Comprehend/'\n",
    "name = 'kroger_tweets.csv'\n",
    "output_name = path + name\n",
    "\n",
    "tweet_df['full_text'].to_csv(output_name, encoding = 'utf-8', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../NLP/Comprehend/kroger_tweets.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
